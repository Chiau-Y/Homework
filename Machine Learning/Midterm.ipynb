{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('./ml-nckues-2020/train.csv') # trianing set\n",
    "data.dropna(axis=0, inplace=True) # drop the data with space\n",
    "data_r = data[data.select_dtypes(include=[np.number]).ge(0).all(1)] # drop the data with the value less than 0\n",
    "\n",
    "X_origin = data_r.iloc[:,1:data_r.shape[1]-1]\n",
    "y_origin = data_r.Label\n",
    "\n",
    "# data_r['Label'].value_counts() # count for the number of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "sel2 = SelectKBest(chi2, k=60) # chi-square distribution, select the best 60 features\n",
    "X_new = sel2.fit_transform(X_origin, y_origin)\n",
    "\n",
    "X_new = pd.DataFrame(X_new) # array to dataframe\n",
    "y_origin.reset_index(drop=True,inplace=True) # reset the index from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.concat([X_new,y_origin],axis=1) \n",
    "\n",
    "excellent = data_r[data_r[\"Label\"]=='Excellent']\n",
    "good = data_r[data_r[\"Label\"]=='good']\n",
    "fair = data_r[data_r[\"Label\"]=='fair']\n",
    "bad = data_r[data_r[\"Label\"]=='bad']\n",
    "\n",
    "data_r_2 = pd.concat([data_r,fair.sample(frac=0.2),fair.sample(frac=0.2),\n",
    "                      fair.sample(frac=0.2),fair.sample(frac=0.2)]) # let the number of data = 1.2*data\n",
    "X = data_r_2.iloc[:,0:data_r_2.shape[1]-1]\n",
    "y = data_r_2.Label\n",
    "\n",
    "# data_r_2['Label'].value_counts() # count for the number of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None) # set down the warning, do not use it in recommend\n",
    "\n",
    "sm = SMOTE(random_state=42) # let the number of data of every label be the same\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "\n",
    "X_temp1 = X_res.iloc[:,0:X_res.shape[1]-2] # the data in binary\n",
    "X_temp2 = X_res.iloc[:,X_res.shape[1]-2:X_res.shape[1]] # the data in real number\n",
    "\n",
    "X_temp1[X_temp1<0.5] = 0 # round for the value into binary\n",
    "X_temp1[X_temp1>=0.5] = 1 # round for the value into binary\n",
    "\n",
    "data_r_2 = pd.concat([X_temp1,X_temp2,y_res],axis=1)\n",
    "\n",
    "# data_r_2['Label'].value_counts() # count for the number of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_random = shuffle(data_r_2) # random the order\n",
    "\n",
    "X_shuffle = data_random.iloc[:,0:data_random.shape[1]-1]\n",
    "y_shuffle = data_random.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # mean to zero, standard deviation to 1\n",
    "scaler.fit(X_shuffle) # set the model according to every feature respectively\n",
    "X_scaler = scaler.transform(X_shuffle)\n",
    "\n",
    "data_val = pd.read_csv('./ml-nckues-2020/val.csv') # validation set\n",
    "X_val_o = data_val.iloc[:,1:data_val.shape[1]-1]\n",
    "y_val = data_val.Label\n",
    "\n",
    "X_val = sel2.transform(X_val_o) # drop the features\n",
    "X_val_scaler = scaler.transform(X_val) # StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing scores :  0.8116129032258065\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# for voting\n",
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, max_features=0.8) # for bagging\n",
    "\n",
    "grb_clf = GradientBoostingClassifier(n_estimators=100,random_state=0)\n",
    "rnd_clf = BaggingClassifier(base_estimator=model_rf, n_estimators=10, random_state=0)\n",
    "xgb_clf = XGBClassifier(silent=0 ,learning_rate= 0.8, max_depth=6, gamma=0,subsample=1, max_delta_step=0,\n",
    "                        colsample_bytree=1, reg_lambda=1, n_estimators=100, seed=1000) \n",
    "lr_clf = LogisticRegression(random_state=0,max_iter=1000,solver='newton-cg')\n",
    "\n",
    "# voting according to the probability(soft)\n",
    "model = VotingClassifier(estimators=[('gb', grb_clf), ('rf', rnd_clf),('xgb',xgb_clf),('lr',lr_clf)],voting='soft')\n",
    "\n",
    "model.fit(X_scaler,y_shuffle) # train the model\n",
    "\n",
    "testing_score = model.score(X_val_scaler,y_val) # validation\n",
    "print('testing scores : ',testing_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('./ml-nckues-2020/test.csv') # testing data\n",
    "\n",
    "X_test = data_test.iloc[:,1:(data_test.shape[1])]\n",
    "X_test_select = sel2.transform(X_test) # drop the features\n",
    "X_test_scaler = scaler.transform(X_test_select) # StandardScaler\n",
    "\n",
    "y_pred = model.predict(X_test_scaler) # pedict\n",
    "\n",
    "y_pred_pd = pd.DataFrame(data=y_pred, columns=['Label']) # save the data to DataFrame\n",
    "\n",
    "# change the label\n",
    "y_pred_pd[y_pred_pd['Label'] == 'bad'] = 4\n",
    "y_pred_pd[y_pred_pd['Label'] == 'fair'] = 3\n",
    "y_pred_pd[y_pred_pd['Label'] == 'good'] = 2\n",
    "y_pred_pd[y_pred_pd['Label'] == 'Excellent'] = 1\n",
    "\n",
    "y_pred_pd = y_pred_pd.reset_index() # reset the index\n",
    "y_pred_pd.to_csv('n96084094_22.csv',index=False) # save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
